{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9664264-5776-42d2-a228-4d3c52b22a4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Why evaluation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560d9dfa-dad8-4b04-bf3a-9fe75c9e7a4d",
   "metadata": {},
   "source": [
    "Before - in AI HERO DATA PREP LONG notebook we learned about function calling and created our first agent using Pydantic AI.\n",
    "\n",
    "But is this agent actually good? Today we will see how to answer this question.\n",
    "\n",
    "In particular, we will cover:\n",
    "\n",
    "-- Build a logging system to track agent interactions\n",
    "\n",
    "-- Create automated evaluation using AI as a judge\n",
    "\n",
    "-- Generate test data automatically\n",
    "\n",
    "-- Measure agent performance with metrics\n",
    "\n",
    "At the end we will have a thoroughly tested agent with performance metrics.\n",
    "\n",
    "In this lesson, we'll use the FAQ database with text search, but it's applicable for any other use case.\n",
    "\n",
    "This is going to be a long lesson, but an important one. Evaluation is critical for building reliable AI systems. Without proper evaluation, you can't tell if your changes improve or hurt performance. You can't compare different approaches. And you can't build confidence before deploying to users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2011f3c0-8612-4272-bc8c-3602ac5bee09",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c07bf-a436-4d6b-a3a5-4a175152bd27",
   "metadata": {},
   "source": [
    "The easiest thing we can do to evaluate an agent is interact with it. We ask something and look at the response. Does it make sense? For most cases, it should.\n",
    "\n",
    "This approach is called \"vibe check\" - we interact with it, and if we like the results, we go ahead and deploy it.\n",
    "\n",
    "If we don't like something, we go back and change things:\n",
    "\n",
    "-- Maybe our chunking method is not suitable? Maybe we need to have a bigger window size?\n",
    "\n",
    "-- Is our system prompt good? Maybe we need more precise instructions?\n",
    "\n",
    "Or we want to change something else\n",
    "\n",
    "And we iterate.\n",
    "\n",
    "It might be okay for the first MVP, but how can we make sure the result at the end is actually good?\n",
    "\n",
    "We need systematic evaluation. Manual testing doesn't scale - you can't manually test every possible input and scenario. With systematic evaluation, we can test hundreds or thousands of cases automatically.\n",
    "\n",
    "We also need to base our decisions on data. It will help us to\n",
    "\n",
    "-- Compare different approaches\n",
    "\n",
    "-- Track improvements\n",
    "\n",
    "-- Identify edge cases\n",
    "\n",
    "We can start collecting this data ourselves: start with vibe checking, but be smart about it. We don't just test it, but also record the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677424a2-ed46-4a9f-8648-8e0a56136ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data scrape function\n",
    "\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter\n",
    "\n",
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "    \n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1831c019-957c-4dfd-911b-038409a4c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAQ documents: 1219\n",
      "Evidently documents: 95\n"
     ]
    }
   ],
   "source": [
    "# download data as we did earlier:\n",
    "dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "evidently_docs = read_repo_data('evidentlyai', 'docs')\n",
    "\n",
    "print(f\"FAQ documents: {len(dtc_faq)}\")\n",
    "print(f\"Evidently documents: {len(evidently_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1373fe23-852b-497a-8ffd-f61775b64923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.minsearch.Index at 0x1ed6ba1bcb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a simple text search index for FAQ data:\n",
    "\n",
    "from minsearch import Index\n",
    "\n",
    "# dtc_faq = read_repo_data('DataTalksClub', 'faq')\n",
    "de_dtc_faq = [d for d in dtc_faq if 'data-engineering' in d['filename']] # we extract only DE = data engineering FAQ\n",
    "\n",
    "faq_index = Index(\n",
    "    text_fields=[\"question\", \"content\"],\n",
    "    keyword_fields=[]\n",
    ")\n",
    "\n",
    "faq_index.fit(de_dtc_faq)\n",
    "\n",
    "# <minsearch.minsearch.Index at 0x1ed6ba1bcb0>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "913f0f76-5bf6-4221-930e-e56fa7572831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üîë Enter your OpenAI API key:  ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
     ]
    }
   ],
   "source": [
    "# we have to enter OpenAI key here and then we can run all cells freely...\n",
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "if not (openai_api_key := os.getenv(\"OPENAI_API_KEY\")):\n",
    "    openai_api_key = getpass(\"üîë Enter your OpenAI API key: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ee1f64c-9840-4ccf-8b72-18372921dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the agent we created yesterday:\n",
    "\n",
    "from typing import List, Any\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "def text_search(query: str) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Perform a text-based search on the FAQ index.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        List[Any]: A list of up to 5 search results returned by the FAQ index.\n",
    "    \"\"\"\n",
    "    return faq_index.search(query, num_results=5)\n",
    "\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant for a  course. \n",
    "\n",
    "Use the search tool to find relevant information from the course materials before answering questions.\n",
    "\n",
    "If you can find specific information through search, use it to provide accurate answers.\n",
    "If the search doesn't return relevant results, let the user know and provide general guidance.\n",
    "\"\"\"\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "agent = Agent(\n",
    "    name=\"faq_agent\",\n",
    "    instructions=system_prompt,\n",
    "    tools=[text_search],\n",
    "    model='gpt-4o-mini'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0f3830-df0c-4c36-bb73-4f1f2adc6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's interact with the agent:\n",
    "question = \"how do I install Kafka in Python?\"\n",
    "result = await agent.run(user_prompt=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "214d8d96-1e87-4692-b2fe-24cb30f0a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4110f775-4eb9-49e0-8db4-c55321a50365",
   "metadata": {},
   "source": [
    "Here's what we want to record:\n",
    "\n",
    "-- The system prompt that we used\n",
    "\n",
    "-- The model\n",
    "\n",
    "-- The user query\n",
    "\n",
    "-- The tools we use\n",
    "\n",
    "-- The responses and the back-and-forth interactions between the LLM and our tools\n",
    "\n",
    "-- The final response\n",
    "\n",
    "To make it simpler, we'll implement a simple logging system ourselves: we will just write logs to json files.\n",
    "\n",
    "You shouldn't use it in production. In practice, you will want to send these logs to some log collection system, or use specialized LLM evaluation tools like Evidently, LangWatch or Arize Phoenix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5845f0a-911e-4977-bcf1-458ab77f0649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's extract all this information from the agent and from the run results:\n",
    "from pydantic_ai.messages import ModelMessagesTypeAdapter\n",
    "\n",
    "\n",
    "def log_entry(agent, messages, source=\"user\"):\n",
    "    tools = []\n",
    "\n",
    "    for ts in agent.toolsets:\n",
    "        tools.extend(ts.tools.keys())\n",
    "\n",
    "    dict_messages = ModelMessagesTypeAdapter.dump_python(messages)\n",
    "\n",
    "    return {\n",
    "        \"agent_name\": agent.name,\n",
    "        \"system_prompt\": agent._instructions,\n",
    "        \"provider\": agent.model.system,\n",
    "        \"model\": agent.model.model_name,\n",
    "        \"tools\": tools,\n",
    "        \"messages\": dict_messages,\n",
    "        \"source\": source\n",
    "    }\n",
    "\n",
    "# This code extracts the key information from our agent:\n",
    "# -- the configuration (name, prompt, model)\n",
    "# -- available tools\n",
    "# -- complete message history (user input, tool calls, responses)\n",
    "# We also use ModelMessagesTypeAdapter.dump_python(messages) to convert internal message format into regular Python dictionaries. \n",
    "# This makes it easier to save it to JSON and process later.\n",
    "# We also add the source parameter. It tracks where the question came from. We start with \"user\" but later we'll use AI-generated queries. \n",
    "# Sometimes it may be important to tell them apart for analysis.\n",
    "# This code is generic so it will work with any Pydantic AI agent. If you use a different library, you'll need to adjust this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b5861b9-ff62-48f9-b5e2-0a2757acca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write these logs to a folder:\n",
    "\n",
    "import json\n",
    "import secrets\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "LOG_DIR = Path('logs')\n",
    "LOG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "def serializer(obj):\n",
    "    if isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    raise TypeError(f\"Type {type(obj)} not serializable\")\n",
    "\n",
    "\n",
    "def log_interaction_to_file(agent, messages, source='user'):\n",
    "    entry = log_entry(agent, messages, source)\n",
    "\n",
    "    ts = entry['messages'][-1]['timestamp']\n",
    "    ts_str = ts.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    rand_hex = secrets.token_hex(3)\n",
    "\n",
    "    filename = f\"{agent.name}_{ts_str}_{rand_hex}.json\"\n",
    "    filepath = LOG_DIR / filename\n",
    "\n",
    "    with filepath.open(\"w\", encoding=\"utf-8\") as f_out:\n",
    "        json.dump(entry, f_out, indent=2, default=serializer)\n",
    "\n",
    "    return filepath\n",
    "\n",
    "# This code above:\n",
    "# Creates a logs directory (if not created previously)\n",
    "# Generates unique filenames with timestamp and random hex\n",
    "# Saves complete interaction logs as JSON files\n",
    "# Handles datetime serialization (using the serialized function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8576867-f31a-414a-9f55-c548a271eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " what do I need to do for the certificate?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To obtain your certificate, you need to follow these requirements:\n",
      "\n",
      "1. **Complete the Peer-Reviewed Capstone Projects**: You must finish the peer-reviewed capstone projects on time. Completing the homework is not mandatory for receiving the certificate, especially if you join the course late.\n",
      "\n",
      "2. **Participate in a Live Cohort**: You can only receive a certificate if you finish the course with a ‚Äúlive‚Äù cohort. Certificates are not awarded for self-paced course completion, as peer reviews need to be conducted while the course is ongoing.\n",
      "\n",
      "3. **Check Your Profile**: There will be an announcement regarding the certificate on Telegram and the course channel. Ensure that your full name is displayed correctly in your course profile, as that is what will appear on the certificate.\n",
      "\n",
      "4. **Access Your Certificate**: After grading is completed and announcements are made, you can follow the instructions provided for generating the certificate document yourself. You will find it in your course profile, which you can access after logging in.\n",
      "\n",
      "For the course edition you‚Äôre enrolled in, the link to your course profile will look something like this: `https://courses.datatalks.club/de-zoomcamp-2025/enrollment`, replacing \"2025\" with the relevant year.\n",
      "\n",
      "Make sure to keep an eye on announcements for the necessary steps to finalize your certificate!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('logs/faq_agent_20251010_192557_3d58d8.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Now we can interact with it and do some vibe checking:\n",
    "    \n",
    "question = input()\n",
    "result = await agent.run(user_prompt=question)\n",
    "print(result.output)\n",
    "log_interaction_to_file(agent, result.new_messages())\n",
    "\n",
    "# This creates a simple interactive loop where:\n",
    "# -- User enters a question\n",
    "# -- Agent processes it and responds\n",
    "# -- Complete interaction is logged to a file\n",
    "\n",
    "# Try these questions:\n",
    "# how do I use docker on windows?\n",
    "# can I join late and get a certificate?\n",
    "# what do I need to do for the certificate?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a899b9eb-87d4-4f59-9f5f-7d6085fcae13",
   "metadata": {},
   "source": [
    "## Adding References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b2e366d-66bf-4d2d-87dc-b901a0e2f7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When interacting with the agent, I noticed one thing: it doesn't include the reference to the original documents.\n",
    "# Let's fix it by adjusting the prompt:\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant for a course.  \n",
    "\n",
    "Use the search tool to find relevant information from the course materials before answering questions.  \n",
    "\n",
    "If you can find specific information through search, use it to provide accurate answers.\n",
    "\n",
    "Always include references by citing the filename of the source material you used.  \n",
    "When citing the reference, replace \"faq-main\" by the full path to the GitHub repository: \"https://github.com/DataTalksClub/faq/blob/main/\"\n",
    "correct link looks like tis - without << /faq-main >> part :\n",
    "<< https://github.com/DataTalksClub/faq/blob/main/_questions/data-engineering-zoomcamp/general/014_3774a79c13_certificate-do-i-need-to-do-the-homeworks-to-get-t.md >> \n",
    "Format: [LINK TITLE](FULL_GITHUB_LINK)\n",
    "\n",
    "If the search doesn't return relevant results, let the user know and provide general guidance.  \n",
    "\"\"\".strip()\n",
    "\n",
    "# Create another version of agent, let's call it faq_agent_v2\n",
    "agent = Agent(\n",
    "    name=\"faq_agent_v2\",\n",
    "    instructions=system_prompt,\n",
    "    tools=[text_search],\n",
    "    model='gpt-4o-mini'\n",
    ")\n",
    "\n",
    "# This is the output I now get for the question \"can I join late and get a certificate?\":\n",
    "\n",
    "# Yes, you can join the course late and still be eligible for a certificate, as long as you complete the required peer-reviewed \n",
    "# capstone projects on time. You do not need to complete the homework assignments if you join late, which allows for flexibility in participation.\n",
    "# However, please note that certificates are only awarded to those who finish the course with a ‚Äúlive‚Äù cohort; \n",
    "# they are not available for those who choose the self-paced mode. \n",
    "# This is because peer-reviewing capstone projects is a requirement that can only be done while the course is active......\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a830263-fc38-4c89-856c-8ee6d4669cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " how do I use docker on windows?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Docker on Windows can vary depending on whether you're using Windows 10 or Windows 11, as well as whether you have the Home or Pro edition. Here are the general steps to get started:\n",
      "\n",
      "1. **Install Docker Desktop**: \n",
      "   - Download and install Docker Desktop from the [official Docker website](https://docs.docker.com/desktop/install/windows-install/).\n",
      "   - Make sure you are running the latest version.\n",
      "\n",
      "2. **Enable Hyper-V or WSL2**:\n",
      "   - **Windows 10 Pro / 11 Pro Users**:\n",
      "     - Ensure Hyper-V is enabled, which Docker can use as a backend. You can find instructions in this [Hyper-V Enablement Guide](https://www.c-sharpcorner.com/article/install-and-configured-docker-desktop-in-windows-10/).\n",
      "   - **Windows 10 Home / 11 Home Users**:\n",
      "     - Since Hyper-V isn't supported, use Windows Subsystem for Linux (WSL2). Check this [WSL Install Guide](https://pureinfotech.com/install-wsl-windows-11/) for detailed instructions.\n",
      "\n",
      "3. **Run Docker with Elevated Privileges**:\n",
      "   - If you encounter connection errors, make sure to run the Docker client with elevated privileges (as an administrator).\n",
      "\n",
      "4. **Troubleshooting**:\n",
      "   - If Docker won't start or is stuck, try switching the containers from Windows to Linux or vice versa by right-clicking the Docker symbol from the running programs.\n",
      "\n",
      "5. **Using Docker Commands**:\n",
      "   - You can run Docker commands in your terminal or command prompt. For example, to run a basic Python container, you can use:\n",
      "     ```bash\n",
      "     docker run -it python:3.9\n",
      "     ```\n",
      "\n",
      "For more details on specific error messages and how to handle them, you can refer to the relevant sections in the course documentation. Here's one specific reference for handling connection errors: [error during connect](https://github.com/DataTalksClub/faq/blob/main/_questions/data-engineering-zoomcamp/module-1/011_46dbe4810d_docker-error-during-connect-in-the-default-daemon.md).\n",
      "\n",
      "If you have any more specific errors or need further details, let me know!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('logs/faq_agent_v2_20251010_200531_229e88.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = input()\n",
    "result = await agent.run(user_prompt=question)\n",
    "print(result.output)\n",
    "log_interaction_to_file(agent, result.new_messages())\n",
    "\n",
    "# NB - links were broken in original code - I checked generated links and model simply merge 2 http adress parts instead of replacing :\n",
    "# Wrong link is\n",
    "# https://github.com/DataTalksClub/faq/blob/main/faq-main/_questions/data-engineering-zoomcamp/general/014_3774a79c13_certificate-do-i-need-to-do-the-homeworks-to-get-t.md\n",
    "# correct link is\n",
    "# https://github.com/DataTalksClub/faq/blob/main/_questions/data-engineering-zoomcamp/general/014_3774a79c13_certificate-do-i-need-to-do-the-homeworks-to-get-t.md\n",
    "# as I manually deleted /faq-main part ...\n",
    "# I FIXED PROMPT ABOVE AND NOW IT WORKS WELL !!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeccb47-c8c9-4d27-a72e-361e4b817b0d",
   "metadata": {},
   "source": [
    "## LLM as a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebae182-dee1-4442-bec7-997a9acdc220",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
